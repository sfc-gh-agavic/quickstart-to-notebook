{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000000",
   "metadata": {
    "name": "introduction_overview"
   },
   "source": [
    "# Getting Started with Snowflake Dynamic Tables\n",
    "\n",
    "This notebook demonstrates how to build declarative data pipelines using Snowflake Dynamic Tables for continuous data transformations, data validation, and alerting. Dynamic Tables automatically refresh based on defined queries and target freshness, simplifying data pipeline management without manual scheduling.\n",
    "\n",
    "**Original Quickstart:** https://quickstarts.snowflake.com/guide/getting_started_with_dynamic_tables/index.html\n",
    "\n",
    "## Prerequisites\n",
    "- **Packages Required:** The Python UDTFs in this demo use the `Faker` package which is available in Snowflake's Anaconda channel. No additional package installation needed.\n",
    "- **Permissions:** Ensure you have privileges to create databases, schemas, warehouses, tables, and dynamic tables.\n",
    "- **Change Tracking:** Will be automatically enabled on base tables as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000001",
   "metadata": {
    "language": "sql",
    "name": "session_context",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Display current session context and connection information\n",
    "SELECT \n",
    "    CURRENT_DATABASE() as current_database,\n",
    "    CURRENT_SCHEMA() as current_schema,\n",
    "    CURRENT_WAREHOUSE() as current_warehouse,\n",
    "    CURRENT_USER() as current_user,\n",
    "    CURRENT_ROLE() as current_role,\n",
    "    CURRENT_REGION() as current_region;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "language": "sql",
    "name": "setup_environment",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Set up database, schema, and warehouse for the demo\n",
    "CREATE DATABASE IF NOT EXISTS DEMO;\n",
    "CREATE SCHEMA IF NOT EXISTS DEMO.DT_DEMO;\n",
    "USE SCHEMA DEMO.DT_DEMO;\n",
    "\n",
    "CREATE WAREHOUSE IF NOT EXISTS XSMALL_WH \n",
    "    WAREHOUSE_TYPE = STANDARD\n",
    "    WAREHOUSE_SIZE = XSMALL\n",
    "    AUTO_SUSPEND = 300\n",
    "    AUTO_RESUME = TRUE;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000003",
   "metadata": {
    "name": "sample_data_overview"
   },
   "source": [
    "## Sample Data Generation\n",
    "\n",
    "We'll create three source tables using Python UDTFs to generate realistic sample data:\n",
    "1. **CUST_INFO** - Customer information with spending limits\n",
    "2. **PROD_STOCK_INV** - Product inventory with stock levels\n",
    "3. **SALESDATA** - Raw sales transactions in JSON format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "language": "sql",
    "name": "create_customer_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Python UDTF to generate customer information data\n",
    "CREATE OR REPLACE FUNCTION gen_cust_info(num_records number)\n",
    "RETURNS TABLE (custid number(10), cname varchar(100), spendlimit number(10,2))\n",
    "LANGUAGE PYTHON\n",
    "RUNTIME_VERSION=3.10\n",
    "HANDLER='CustTab'\n",
    "PACKAGES = ('Faker')\n",
    "AS $$\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "# Generate a list of customers  \n",
    "\n",
    "class CustTab:\n",
    "    # Generate multiple customer records\n",
    "    def process(self, num_records):\n",
    "        customer_id = 1000 # Starting customer ID                 \n",
    "        for _ in range(num_records):\n",
    "            custid = customer_id + 1\n",
    "            cname = fake.name()\n",
    "            spendlimit = round(random.uniform(1000, 10000),2)\n",
    "            customer_id += 1\n",
    "            yield (custid,cname,spendlimit)\n",
    "$$;\n",
    "\n",
    "CREATE OR REPLACE TABLE cust_info AS \n",
    "SELECT * FROM table(gen_cust_info(1000)) ORDER BY 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000005",
   "metadata": {
    "language": "sql",
    "name": "create_product_inventory",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Python UDTF to generate product inventory data\n",
    "CREATE OR REPLACE FUNCTION gen_prod_inv(num_records number)\n",
    "RETURNS TABLE (pid number(10), pname varchar(100), stock number(10,2), stockdate date)\n",
    "LANGUAGE PYTHON\n",
    "RUNTIME_VERSION=3.10\n",
    "HANDLER='ProdTab'\n",
    "PACKAGES = ('Faker')\n",
    "AS $$\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "fake = Faker()\n",
    "\n",
    "class ProdTab:\n",
    "    # Generate multiple product records\n",
    "    def process(self, num_records):\n",
    "        product_id = 100 # Starting customer ID                 \n",
    "        for _ in range(num_records):\n",
    "            pid = product_id + 1\n",
    "            pname = fake.catch_phrase()\n",
    "            stock = round(random.uniform(500, 1000),0)\n",
    "            # Get the current date\n",
    "            current_date = datetime.now()\n",
    "            \n",
    "            # Calculate the maximum date (3 months from now)\n",
    "            min_date = current_date - timedelta(days=90)\n",
    "            \n",
    "            # Generate a random date within the date range\n",
    "            stockdate = fake.date_between_dates(min_date,current_date)\n",
    "\n",
    "            product_id += 1\n",
    "            yield (pid,pname,stock,stockdate)\n",
    "$$;\n",
    "\n",
    "CREATE OR REPLACE TABLE prod_stock_inv AS \n",
    "SELECT * FROM table(gen_prod_inv(100)) ORDER BY 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000006",
   "metadata": {
    "language": "sql",
    "name": "create_sales_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Python UDTF to generate sales transaction data in JSON format\n",
    "CREATE OR REPLACE FUNCTION gen_cust_purchase(num_records number,ndays number)\n",
    "RETURNS TABLE (custid number(10), purchase variant)\n",
    "LANGUAGE PYTHON\n",
    "RUNTIME_VERSION=3.10\n",
    "HANDLER='genCustPurchase'\n",
    "PACKAGES = ('Faker')\n",
    "AS $$\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "class genCustPurchase:\n",
    "    # Generate multiple customer purchase records\n",
    "    def process(self, num_records,ndays):       \n",
    "        for _ in range(num_records):\n",
    "            c_id = fake.random_int(min=1001, max=1999)\n",
    "            \n",
    "            customer_purchase = {\n",
    "                'custid': c_id,\n",
    "                'purchased': []\n",
    "            }\n",
    "            # Get the current date\n",
    "            current_date = datetime.now()\n",
    "            \n",
    "            # Calculate the maximum date (days from now)\n",
    "            min_date = current_date - timedelta(days=ndays)\n",
    "            \n",
    "            # Generate a random date within the date range\n",
    "            pdate = fake.date_between_dates(min_date,current_date)\n",
    "            \n",
    "            purchase = {\n",
    "                'prodid': fake.random_int(min=101, max=199),\n",
    "                'quantity': fake.random_int(min=1, max=5),\n",
    "                'purchase_amount': round(random.uniform(10, 1000),2),\n",
    "                'purchase_date': pdate\n",
    "            }\n",
    "            customer_purchase['purchased'].append(purchase)\n",
    "            \n",
    "            yield (c_id,purchase)\n",
    "$$;\n",
    "\n",
    "-- Create table and insert records \n",
    "CREATE OR REPLACE TABLE salesdata AS \n",
    "SELECT * FROM table(gen_cust_purchase(10000,10));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000007",
   "metadata": {
    "language": "sql",
    "name": "verify_sample_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Verify sample data has been created successfully\n",
    "-- Customer information table, each customer has spending limits\n",
    "SELECT 'CUST_INFO' as table_name, COUNT(*) as record_count FROM cust_info\n",
    "UNION ALL\n",
    "-- Product stock table, each product has stock level from fulfillment day\n",
    "SELECT 'PROD_STOCK_INV' as table_name, COUNT(*) as record_count FROM prod_stock_inv\n",
    "UNION ALL\n",
    "-- Sales data for products purchased online by various customers\n",
    "SELECT 'SALESDATA' as table_name, COUNT(*) as record_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000008",
   "metadata": {
    "language": "sql",
    "name": "preview_customer_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Preview sample data from customer info table\n",
    "SELECT * FROM cust_info LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000009",
   "metadata": {
    "language": "sql",
    "name": "preview_product_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Preview sample data from product inventory table\n",
    "SELECT * FROM prod_stock_inv LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000010",
   "metadata": {
    "language": "sql",
    "name": "preview_sales_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Preview sample data from sales transactions table\n",
    "SELECT * FROM salesdata LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000011",
   "metadata": {
    "name": "pipeline_overview"
   },
   "source": [
    "## Building the Dynamic Tables Pipeline\n",
    "\n",
    "Now we'll create a series of Dynamic Tables to build our data pipeline. The pipeline will:\n",
    "1. Extract and transform sales data from JSON format\n",
    "2. Join with customer and product information \n",
    "3. Create sales reports with SCD Type 2 transformations\n",
    "4. Build cumulative totals using Python UDTFs\n",
    "5. Create data validation and alerting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000012",
   "metadata": {
    "language": "sql",
    "name": "customer_sales_history_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create first Dynamic Table: Extract sales data and join with customer info\n",
    "USE SCHEMA DEMO.DT_DEMO;\n",
    "\n",
    "CREATE OR REPLACE DYNAMIC TABLE customer_sales_data_history\n",
    "    LAG='DOWNSTREAM'\n",
    "    WAREHOUSE=XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    s.custid as customer_id,\n",
    "    c.cname as customer_name,\n",
    "    s.purchase:\"prodid\"::number(5) as product_id,\n",
    "    s.purchase:\"purchase_amount\"::number(10) as saleprice,\n",
    "    s.purchase:\"quantity\"::number(5) as quantity,\n",
    "    s.purchase:\"purchase_date\"::date as salesdate\n",
    "FROM\n",
    "    cust_info c INNER JOIN salesdata s ON c.custid = s.custid;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000013",
   "metadata": {
    "language": "sql",
    "name": "verify_customer_sales_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Verify the first Dynamic Table and check record count\n",
    "SELECT * FROM customer_sales_data_history LIMIT 10;\n",
    "SELECT COUNT(*) as total_records FROM customer_sales_data_history;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000014",
   "metadata": {
    "language": "sql",
    "name": "salesreport_scd_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create second Dynamic Table: Sales report with SCD Type 2 transformation\n",
    "CREATE OR REPLACE DYNAMIC TABLE salesreport\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE=XSMALL_WH\n",
    "AS\n",
    "    SELECT\n",
    "        t1.customer_id,\n",
    "        t1.customer_name, \n",
    "        t1.product_id,\n",
    "        p.pname as product_name,\n",
    "        t1.saleprice,\n",
    "        t1.quantity,\n",
    "        (t1.saleprice/t1.quantity) as unitsalesprice,\n",
    "        t1.salesdate as CreationTime,\n",
    "        customer_id || '-' || t1.product_id  || '-' || t1.salesdate AS CUSTOMER_SK,\n",
    "        LEAD(CreationTime) OVER (PARTITION BY t1.customer_id ORDER BY CreationTime ASC) AS END_TIME\n",
    "    FROM \n",
    "        customer_sales_data_history t1 INNER JOIN prod_stock_inv p \n",
    "        ON t1.product_id = p.pid;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000015",
   "metadata": {
    "language": "sql",
    "name": "verify_salesreport_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Verify the sales report Dynamic Table\n",
    "SELECT * FROM salesreport LIMIT 10;\n",
    "SELECT COUNT(*) as total_records FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000016",
   "metadata": {
    "language": "sql",
    "name": "test_pipeline_insert",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Test the Dynamic Tables pipeline by adding new data\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(10000,2));\n",
    "\n",
    "-- Check raw base table\n",
    "SELECT COUNT(*) as salesdata_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000017",
   "metadata": {
    "language": "sql",
    "name": "check_dt_refresh",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Check Dynamic Tables after refresh (wait a minute for automatic refresh)\n",
    "SELECT COUNT(*) as customer_sales_history_count FROM customer_sales_data_history;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "basic_incremental_overview"
   },
   "source": [
    "## Query Types Showcase: Basic Incremental Operations\n",
    "\n",
    "Dynamic Tables support different types of queries that are optimized for incremental refresh mode. These operations can efficiently process only the changed data rather than requiring a full table refresh. Let's demonstrate the four basic incremental operation types:\n",
    "\n",
    "1. **Simple Aggregations** - Basic SUM, COUNT, AVG operations on streaming data\n",
    "2. **Filter Operations** - WHERE clauses filtering on timestamp or ID columns  \n",
    "3. **Simple Joins** - INNER and LEFT JOINs between tables with proper join keys\n",
    "4. **UNION Operations** - Combining similar datasets with UNION ALL\n",
    "\n",
    "Each example will create a Dynamic Table that showcases these incremental-friendly patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "daily_sales_summary_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 1: Simple Aggregations Dynamic Table\n",
    "-- Demonstrates basic SUM, COUNT, AVG operations optimal for incremental refresh\n",
    "CREATE OR REPLACE DYNAMIC TABLE daily_sales_summary\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    DATE(sr.creationtime) as sales_date,\n",
    "    COUNT(*) as total_transactions,\n",
    "    SUM(sr.saleprice) as total_revenue,\n",
    "    AVG(sr.saleprice) as avg_transaction_amount,\n",
    "    SUM(sr.quantity) as total_units_sold,\n",
    "    COUNT(DISTINCT sr.customer_id) as unique_customers\n",
    "FROM salesreport sr\n",
    "GROUP BY DATE(sr.creationtime);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "high_value_recent_sales_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 2: Filter Operations Dynamic Table  \n",
    "-- Demonstrates WHERE clauses filtering on timestamp/ID columns for incremental processing\n",
    "CREATE OR REPLACE DYNAMIC TABLE high_value_recent_sales\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    sr.customer_id,\n",
    "    sr.customer_name,\n",
    "    sr.product_id,\n",
    "    sr.product_name,\n",
    "    sr.saleprice,\n",
    "    sr.quantity,\n",
    "    sr.creationtime\n",
    "FROM salesreport sr\n",
    "WHERE \n",
    "    sr.saleprice > 500  -- Filter for high-value transactions\n",
    "    AND sr.creationtime >= DATEADD('day', -7, CURRENT_DATE())  -- Recent transactions only\n",
    "    AND sr.customer_id BETWEEN 1500 AND 1800;  -- Specific customer segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "rolling_window_alternative"
   },
   "outputs": [],
   "source": [
    "-- Alternative Option 2: Rolling 7-day window using a separate staging table\n",
    "-- This approach creates a \"control table\" to manage the date window\n",
    "-- First create a control table for date management:\n",
    "-- CREATE TABLE date_control (cutoff_date DATE);\n",
    "-- INSERT INTO date_control VALUES (DATEADD('day', -7, CURRENT_DATE()));\n",
    "\n",
    "-- Then create the dynamic table with static reference:\n",
    "-- CREATE OR REPLACE DYNAMIC TABLE high_value_recent_sales_rolling\n",
    "--     LAG = '1 MINUTE'\n",
    "--     WAREHOUSE = XSMALL_WH\n",
    "-- AS\n",
    "-- SELECT \n",
    "--     sr.customer_id,\n",
    "--     sr.customer_name,\n",
    "--     sr.product_id,\n",
    "--     sr.product_name,\n",
    "--     sr.saleprice,\n",
    "--     sr.quantity,\n",
    "--     sr.creationtime\n",
    "-- FROM salesreport sr\n",
    "-- CROSS JOIN date_control dc\n",
    "-- WHERE \n",
    "--     sr.saleprice > 500  \n",
    "--     AND sr.creationtime >= dc.cutoff_date  -- Reference to control table\n",
    "--     AND sr.customer_id BETWEEN 1500 AND 1800;\n",
    "\n",
    "-- To update the window, simply update the control table:\n",
    "-- UPDATE date_control SET cutoff_date = DATEADD('day', -7, CURRENT_DATE());\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "customer_purchase_analysis_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 3: Simple Joins Dynamic Table\n",
    "-- Demonstrates INNER and LEFT JOINs with proper join keys for incremental processing  \n",
    "CREATE OR REPLACE DYNAMIC TABLE customer_purchase_analysis\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    c.custid,\n",
    "    c.cname as customer_name,\n",
    "    c.spendlimit,\n",
    "    sr.saleprice,\n",
    "    sr.quantity,\n",
    "    sr.creationtime,\n",
    "    -- Calculate spending as percentage of limit\n",
    "    ROUND((sr.saleprice / c.spendlimit) * 100, 2) as spend_percentage,\n",
    "    -- Flag customers approaching their limit\n",
    "    CASE \n",
    "        WHEN (sr.saleprice / c.spendlimit) > 0.8 THEN 'High Risk'\n",
    "        WHEN (sr.saleprice / c.spendlimit) > 0.6 THEN 'Medium Risk'  \n",
    "        ELSE 'Low Risk'\n",
    "    END as risk_category\n",
    "FROM cust_info c\n",
    "INNER JOIN salesreport sr ON c.custid = sr.customer_id;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "unified_transaction_log_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 4: UNION Operations Dynamic Table\n",
    "-- Demonstrates combining similar datasets with UNION ALL for incremental processing\n",
    "CREATE OR REPLACE DYNAMIC TABLE unified_transaction_log\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "-- High value transactions (>= 750)\n",
    "SELECT \n",
    "    'HIGH_VALUE' as transaction_category,\n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    saleprice,\n",
    "    quantity,\n",
    "    creationtime,\n",
    "    'Premium Customer' as customer_tier\n",
    "FROM salesreport \n",
    "WHERE saleprice >= 750\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Medium value transactions (250-749)\n",
    "SELECT \n",
    "    'MEDIUM_VALUE' as transaction_category,\n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    saleprice,\n",
    "    quantity,\n",
    "    creationtime,\n",
    "    'Standard Customer' as customer_tier\n",
    "FROM salesreport \n",
    "WHERE saleprice >= 250 AND saleprice < 750\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Low value transactions (< 250)\n",
    "SELECT \n",
    "    'LOW_VALUE' as transaction_category,\n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    saleprice,\n",
    "    quantity,\n",
    "    creationtime,\n",
    "    'Basic Customer' as customer_tier\n",
    "FROM salesreport \n",
    "WHERE saleprice < 250;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "verify_basic_incremental_dts"
   },
   "outputs": [],
   "source": [
    "-- Verify the new Dynamic Tables were created successfully\n",
    "SELECT 'DAILY_SALES_SUMMARY' as table_name, COUNT(*) as record_count FROM daily_sales_summary\n",
    "UNION ALL\n",
    "SELECT 'HIGH_VALUE_RECENT_SALES' as table_name, COUNT(*) as record_count FROM high_value_recent_sales\n",
    "UNION ALL\n",
    "SELECT 'CUSTOMER_PURCHASE_ANALYSIS' as table_name, COUNT(*) as record_count FROM customer_purchase_analysis\n",
    "UNION ALL\n",
    "SELECT 'UNIFIED_TRANSACTION_LOG' as table_name, COUNT(*) as record_count FROM unified_transaction_log;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "incremental_testing_overview"
   },
   "source": [
    "### Testing Incremental Refresh Behavior\n",
    "\n",
    "Now let's test the incremental refresh behavior of our Dynamic Tables by:\n",
    "1. Adding new sales data to trigger automatic refreshes\n",
    "2. Monitoring the refresh history to verify incremental processing\n",
    "3. Comparing before/after record counts to confirm updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "insert_test_data"
   },
   "outputs": [],
   "source": [
    "-- Insert new sales data to trigger Dynamic Table refreshes\n",
    "-- This will demonstrate incremental processing capabilities\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(5000, 3));\n",
    "\n",
    "-- Check the updated base table count\n",
    "SELECT 'SALESDATA_AFTER_INSERT' as table_name, COUNT(*) as record_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "check_updated_counts"
   },
   "outputs": [],
   "source": [
    "-- Wait a moment for Dynamic Tables to refresh, then check updated counts\n",
    "-- The LAG='1 MINUTE' setting means tables should refresh within a minute\n",
    "SELECT 'DAILY_SALES_SUMMARY_AFTER' as table_name, COUNT(*) as record_count FROM daily_sales_summary\n",
    "UNION ALL\n",
    "SELECT 'HIGH_VALUE_RECENT_SALES_AFTER' as table_name, COUNT(*) as record_count FROM high_value_recent_sales\n",
    "UNION ALL\n",
    "SELECT 'CUSTOMER_PURCHASE_ANALYSIS_AFTER' as table_name, COUNT(*) as record_count FROM customer_purchase_analysis\n",
    "UNION ALL\n",
    "SELECT 'UNIFIED_TRANSACTION_LOG_AFTER' as table_name, COUNT(*) as record_count FROM unified_transaction_log;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "check_refresh_history"
   },
   "outputs": [],
   "source": [
    "-- Check Dynamic Table refresh history to verify incremental vs full refresh behavior\n",
    "-- REFRESH_TYPE indicates whether the refresh was 'INCREMENTAL' or 'FULL'\n",
    "-- After fixing high_value_recent_sales (removed CURRENT_DATE()), it should now show INCREMENTAL refreshes\n",
    "SELECT \n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_TYPE,\n",
    "    REFRESH_REASON,\n",
    "    DATA_TIMESTAMP,\n",
    "    REFRESH_START_TIME,\n",
    "    REFRESH_END_TIME,\n",
    "    CREDITS_USED,\n",
    "    BYTES_SCANNED,\n",
    "    ROWS_PRODUCED\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('DAILY_SALES_SUMMARY', 'HIGH_VALUE_RECENT_SALES', 'CUSTOMER_PURCHASE_ANALYSIS', 'UNIFIED_TRANSACTION_LOG')\n",
    "    AND REFRESH_START_TIME >= DATEADD('hour', -1, CURRENT_TIMESTAMP())\n",
    "ORDER BY \n",
    "    NAME, DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "query_types_summary"
   },
   "source": [
    "### Query Types Summary\n",
    "\n",
    "The Dynamic Tables we just created demonstrate the four basic incremental operation patterns:\n",
    "\n",
    "1. **`daily_sales_summary`** - Simple aggregations (SUM, COUNT, AVG) that can efficiently process only new data\n",
    "2. **`high_value_recent_sales`** - Filter operations using WHERE clauses with static dates and ID columns (fixed to use static date instead of CURRENT_DATE() for incremental processing)  \n",
    "3. **`customer_purchase_analysis`** - Simple joins between tables using proper join keys\n",
    "4. **`unified_transaction_log`** - UNION operations combining similar datasets with consistent structure\n",
    "\n",
    "When you check the refresh history above, you should see `REFRESH_TYPE = 'INCREMENTAL'` for these tables when they process new data, demonstrating their efficiency. The `BYTES_SCANNED` and `CREDITS_USED` metrics will also be lower compared to full refresh operations, showing the performance benefits of incremental processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "complex_incremental_overview"
   },
   "source": [
    "## Query Types Showcase: Complex Incremental Operations\n",
    "\n",
    "These examples demonstrate more sophisticated query patterns that still support incremental refresh mode. These operations are more complex than basic aggregations but can still efficiently process only changed data:\n",
    "\n",
    "1. **LATERAL with FLATTEN()** - Parsing nested JSON/VARIANT data using LATERAL FLATTEN to extract array elements\n",
    "2. **CTEs with Incremental Logic** - Common Table Expressions that build incremental transformations step by step  \n",
    "3. **Window Functions (Incremental-Safe)** - LAG, LEAD, FIRST_VALUE, LAST_VALUE over partitioned data\n",
    "4. **Incremental Deduplication** - ROW_NUMBER() OVER (PARTITION BY key ORDER BY timestamp) for latest records\n",
    "\n",
    "These patterns maintain incremental refresh capability while providing advanced analytical functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "json_sales_flattened_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 1: LATERAL with FLATTEN() Dynamic Table\n",
    "-- Demonstrates parsing nested JSON/VARIANT data for incremental processing\n",
    "CREATE OR REPLACE DYNAMIC TABLE json_sales_flattened\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    s.custid,\n",
    "    f.value:\"prodid\"::number as product_id,\n",
    "    f.value:\"quantity\"::number as quantity,\n",
    "    f.value:\"purchase_amount\"::number(10,2) as amount,\n",
    "    f.value:\"purchase_date\"::date as purchase_date,\n",
    "    CURRENT_TIMESTAMP() as processed_timestamp\n",
    "FROM salesdata s,\n",
    "LATERAL FLATTEN(input => ARRAY_CONSTRUCT(s.purchase)) f\n",
    "WHERE f.value IS NOT NULL;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "customer_segmentation_cte_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 2: CTEs with Incremental Logic Dynamic Table\n",
    "-- Demonstrates multi-step transformations using Common Table Expressions\n",
    "CREATE OR REPLACE DYNAMIC TABLE customer_segmentation_cte\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "WITH customer_totals AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        SUM(saleprice) as total_spent,\n",
    "        COUNT(*) as transaction_count,\n",
    "        AVG(saleprice) as avg_transaction\n",
    "    FROM salesreport\n",
    "    GROUP BY customer_id, customer_name\n",
    "),\n",
    "customer_percentiles AS (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        total_spent,\n",
    "        transaction_count,\n",
    "        avg_transaction,\n",
    "        NTILE(5) OVER (ORDER BY total_spent) as spending_quintile\n",
    "    FROM customer_totals\n",
    ")\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    total_spent,\n",
    "    transaction_count,\n",
    "    avg_transaction,\n",
    "    spending_quintile,\n",
    "    CASE \n",
    "        WHEN spending_quintile = 5 THEN 'VIP'\n",
    "        WHEN spending_quintile >= 4 THEN 'High Value'\n",
    "        WHEN spending_quintile >= 3 THEN 'Medium Value'\n",
    "        ELSE 'Standard'\n",
    "    END as customer_tier\n",
    "FROM customer_percentiles;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "sales_trends_window_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 3: Window Functions (Incremental-Safe) Dynamic Table\n",
    "-- Demonstrates LAG, LEAD, FIRST_VALUE, LAST_VALUE over partitioned data\n",
    "CREATE OR REPLACE DYNAMIC TABLE sales_trends_window\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    saleprice,\n",
    "    creationtime,\n",
    "    -- Previous transaction amount for this customer\n",
    "    LAG(saleprice, 1) OVER (PARTITION BY customer_id ORDER BY creationtime) as prev_transaction,\n",
    "    -- Next transaction amount for this customer  \n",
    "    LEAD(saleprice, 1) OVER (PARTITION BY customer_id ORDER BY creationtime) as next_transaction,\n",
    "    -- First transaction amount for this customer\n",
    "    FIRST_VALUE(saleprice) OVER (PARTITION BY customer_id ORDER BY creationtime) as first_transaction,\n",
    "    -- Most recent transaction amount for this customer\n",
    "    LAST_VALUE(saleprice) OVER (PARTITION BY customer_id ORDER BY creationtime ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) as latest_transaction,\n",
    "    -- Calculate spending trend\n",
    "    CASE \n",
    "        WHEN LAG(saleprice, 1) OVER (PARTITION BY customer_id ORDER BY creationtime) IS NULL THEN 'First Purchase'\n",
    "        WHEN saleprice > LAG(saleprice, 1) OVER (PARTITION BY customer_id ORDER BY creationtime) THEN 'Increasing'\n",
    "        WHEN saleprice < LAG(saleprice, 1) OVER (PARTITION BY customer_id ORDER BY creationtime) THEN 'Decreasing'\n",
    "        ELSE 'Stable'\n",
    "    END as spending_trend\n",
    "FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "latest_customer_transactions_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 4: Incremental Deduplication Dynamic Table\n",
    "-- Demonstrates ROW_NUMBER() OVER (PARTITION BY key ORDER BY timestamp) for latest records\n",
    "CREATE OR REPLACE DYNAMIC TABLE latest_customer_transactions\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    product_name,\n",
    "    saleprice,\n",
    "    quantity,\n",
    "    creationtime,\n",
    "    customer_sk\n",
    "FROM (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        product_id,\n",
    "        product_name,\n",
    "        saleprice,\n",
    "        quantity,\n",
    "        creationtime,\n",
    "        customer_sk,\n",
    "        -- Get the latest transaction for each customer-product combination\n",
    "        ROW_NUMBER() OVER (PARTITION BY customer_id, product_id ORDER BY creationtime DESC) as rn\n",
    "    FROM salesreport\n",
    ") ranked\n",
    "WHERE rn = 1  -- Only keep the most recent transaction per customer-product pair\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY customer_id, product_id ORDER BY creationtime DESC) = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "verify_complex_incremental_dts"
   },
   "outputs": [],
   "source": [
    "-- Verify Complex Incremental Operations Dynamic Tables\n",
    "SELECT 'JSON_SALES_FLATTENED' as table_name, COUNT(*) as record_count FROM json_sales_flattened\n",
    "UNION ALL\n",
    "SELECT 'CUSTOMER_SEGMENTATION_CTE' as table_name, COUNT(*) as record_count FROM customer_segmentation_cte\n",
    "UNION ALL\n",
    "SELECT 'SALES_TRENDS_WINDOW' as table_name, COUNT(*) as record_count FROM sales_trends_window\n",
    "UNION ALL\n",
    "SELECT 'LATEST_CUSTOMER_TRANSACTIONS' as table_name, COUNT(*) as record_count FROM latest_customer_transactions;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "test_complex_incremental"
   },
   "outputs": [],
   "source": [
    "-- Test Complex Incremental Operations - Insert new data\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(3000, 2));\n",
    "\n",
    "-- Check updated base table count\n",
    "SELECT 'SALESDATA_COMPLEX_TEST' as table_name, COUNT(*) as record_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "check_complex_refresh_history"
   },
   "outputs": [],
   "source": [
    "-- Check Complex Incremental Operations refresh history\n",
    "-- These should show REFRESH_TYPE = 'INCREMENTAL' demonstrating advanced incremental capabilities\n",
    "SELECT \n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_TYPE,\n",
    "    REFRESH_REASON,\n",
    "    DATA_TIMESTAMP,\n",
    "    REFRESH_START_TIME,\n",
    "    REFRESH_END_TIME,\n",
    "    CREDITS_USED,\n",
    "    BYTES_SCANNED,\n",
    "    ROWS_PRODUCED\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('JSON_SALES_FLATTENED', 'CUSTOMER_SEGMENTATION_CTE', 'SALES_TRENDS_WINDOW', 'LATEST_CUSTOMER_TRANSACTIONS')\n",
    "    AND REFRESH_START_TIME >= DATEADD('hour', -1, CURRENT_TIMESTAMP())\n",
    "ORDER BY \n",
    "    NAME, DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "non_deterministic_overview"
   },
   "source": [
    "## Query Types Showcase: Non-Deterministic Functions (Full Refresh Mode)\n",
    "\n",
    "These examples demonstrate query patterns that require **FULL refresh mode** due to their non-deterministic nature. These operations cannot be incrementally computed because they depend on complete dataset ordering or produce different results with the same input:\n",
    "\n",
    "1. **ANY_VALUE Aggregations** - Selecting arbitrary values from grouped data where order is not guaranteed\n",
    "2. **RANK Functions** - RANK() and DENSE_RANK() operations that depend on complete dataset ordering  \n",
    "3. **ROW_NUMBER Global Ordering** - ROW_NUMBER() without proper partitioning that requires full dataset scan\n",
    "\n",
    "**Important:** These Dynamic Tables will show `REFRESH_TYPE = 'FULL'` in the refresh history, demonstrating when full refresh is necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "any_value_customer_sample_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 1: ANY_VALUE Aggregations Dynamic Table (Full Refresh Mode)\n",
    "-- Demonstrates arbitrary value selection requiring full dataset knowledge\n",
    "CREATE OR REPLACE DYNAMIC TABLE any_value_customer_sample\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    DATE(creationtime) as sales_date,\n",
    "    COUNT(*) as total_transactions,\n",
    "    -- ANY_VALUE is non-deterministic - could return different values with same input\n",
    "    ANY_VALUE(customer_name) as sample_customer_name,\n",
    "    ANY_VALUE(product_name) as sample_product_name,\n",
    "    ANY_VALUE(saleprice) as sample_transaction_amount,\n",
    "    -- These functions return arbitrary values from each group\n",
    "    ANY_VALUE(customer_id) as sample_customer_id,\n",
    "    ANY_VALUE(product_id) as sample_product_id,\n",
    "    MAX(saleprice) as max_transaction,\n",
    "    MIN(saleprice) as min_transaction,\n",
    "    AVG(saleprice) as avg_transaction\n",
    "FROM salesreport\n",
    "GROUP BY DATE(creationtime);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "customer_spending_ranks_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 2: RANK Functions Dynamic Table (Full Refresh Mode)  \n",
    "-- Demonstrates ranking operations requiring complete dataset ordering\n",
    "CREATE OR REPLACE DYNAMIC TABLE customer_spending_ranks\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    total_spent,\n",
    "    transaction_count,\n",
    "    -- RANK and DENSE_RANK require full dataset to determine accurate rankings\n",
    "    RANK() OVER (ORDER BY total_spent DESC) as spending_rank,\n",
    "    DENSE_RANK() OVER (ORDER BY total_spent DESC) as dense_spending_rank,\n",
    "    PERCENT_RANK() OVER (ORDER BY total_spent) as spending_percentile,\n",
    "    -- These rankings can change when new data arrives\n",
    "    RANK() OVER (ORDER BY transaction_count DESC) as transaction_count_rank,\n",
    "    DENSE_RANK() OVER (ORDER BY transaction_count DESC) as dense_transaction_rank\n",
    "FROM (\n",
    "    SELECT \n",
    "        customer_id,\n",
    "        customer_name,\n",
    "        SUM(saleprice) as total_spent,\n",
    "        COUNT(*) as transaction_count\n",
    "    FROM salesreport\n",
    "    GROUP BY customer_id, customer_name\n",
    ") customer_aggregates;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "global_transaction_sequence_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 3: ROW_NUMBER Global Ordering Dynamic Table (Full Refresh Mode)\n",
    "-- Demonstrates global row numbering requiring full dataset scan\n",
    "CREATE OR REPLACE DYNAMIC TABLE global_transaction_sequence\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    product_name,\n",
    "    saleprice,\n",
    "    creationtime,\n",
    "    -- Global ROW_NUMBER without partitioning requires full dataset knowledge\n",
    "    ROW_NUMBER() OVER (ORDER BY creationtime, customer_id, product_id) as global_transaction_sequence,\n",
    "    ROW_NUMBER() OVER (ORDER BY saleprice DESC) as high_value_sequence,\n",
    "    ROW_NUMBER() OVER (ORDER BY saleprice ASC) as low_value_sequence,\n",
    "    -- These sequences will change when new data is inserted anywhere in the ordered set\n",
    "    CASE \n",
    "        WHEN ROW_NUMBER() OVER (ORDER BY saleprice DESC) <= 100 THEN 'Top 100 Transaction'\n",
    "        WHEN ROW_NUMBER() OVER (ORDER BY saleprice ASC) <= 100 THEN 'Bottom 100 Transaction'\n",
    "        ELSE 'Middle Transaction'\n",
    "    END as transaction_classification\n",
    "FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "verify_non_deterministic_dts"
   },
   "outputs": [],
   "source": [
    "-- Verify Non-Deterministic Functions Dynamic Tables\n",
    "SELECT 'ANY_VALUE_CUSTOMER_SAMPLE' as table_name, COUNT(*) as record_count FROM any_value_customer_sample\n",
    "UNION ALL\n",
    "SELECT 'CUSTOMER_SPENDING_RANKS' as table_name, COUNT(*) as record_count FROM customer_spending_ranks\n",
    "UNION ALL\n",
    "SELECT 'GLOBAL_TRANSACTION_SEQUENCE' as table_name, COUNT(*) as record_count FROM global_transaction_sequence;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "test_non_deterministic"
   },
   "outputs": [],
   "source": [
    "-- Test Non-Deterministic Functions - Insert new data\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(2000, 1));\n",
    "\n",
    "-- Check updated base table count\n",
    "SELECT 'SALESDATA_NON_DETERMINISTIC_TEST' as table_name, COUNT(*) as record_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "check_non_deterministic_history"
   },
   "outputs": [],
   "source": [
    "-- Check Non-Deterministic Functions refresh history\n",
    "-- These should show REFRESH_TYPE = 'FULL' due to non-deterministic query patterns\n",
    "SELECT \n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_TYPE,\n",
    "    REFRESH_REASON,\n",
    "    DATA_TIMESTAMP,\n",
    "    REFRESH_START_TIME,\n",
    "    REFRESH_END_TIME,\n",
    "    CREDITS_USED,\n",
    "    BYTES_SCANNED,\n",
    "    ROWS_PRODUCED,\n",
    "    -- Highlight full refresh operations\n",
    "    CASE \n",
    "        WHEN REFRESH_TYPE = 'FULL' THEN '⚠ FULL REFRESH REQUIRED'\n",
    "        WHEN REFRESH_TYPE = 'INCREMENTAL' THEN '✓ INCREMENTAL REFRESH'\n",
    "        ELSE '? UNKNOWN TYPE'\n",
    "    END as refresh_mode_indicator\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('ANY_VALUE_CUSTOMER_SAMPLE', 'CUSTOMER_SPENDING_RANKS', 'GLOBAL_TRANSACTION_SEQUENCE')\n",
    "    AND REFRESH_START_TIME >= DATEADD('hour', -1, CURRENT_TIMESTAMP())\n",
    "ORDER BY \n",
    "    NAME, DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    },
    "name": "complex_analytics_overview"
   },
   "source": [
    "## Query Types Showcase: Complex Analytics (Full Refresh Mode)\n",
    "\n",
    "These examples demonstrate advanced analytical functions that require **FULL refresh mode** due to their computational complexity. These operations need complete dataset access to produce accurate results:\n",
    "\n",
    "1. **Percentile Functions** - PERCENTILE_CONT, PERCENTILE_DISC requiring full dataset analysis\n",
    "2. **Cross-Partition Analytics** - Window functions that span across all data without proper partitioning\n",
    "3. **Complex Statistical Functions** - STDDEV, VARIANCE, CORR over entire dataset\n",
    "\n",
    "**Important:** These Dynamic Tables will show `REFRESH_TYPE = 'FULL'` due to their analytical complexity and need for complete dataset knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "sales_percentile_analysis_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 1: Percentile Functions Dynamic Table (Full Refresh Mode)\n",
    "-- Demonstrates percentile calculations requiring full dataset analysis\n",
    "CREATE OR REPLACE DYNAMIC TABLE sales_percentile_analysis\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    'SALES_PERCENTILES' as analysis_type,\n",
    "    COUNT(*) as total_transactions,\n",
    "    -- Percentile functions require full dataset to calculate accurate percentiles\n",
    "    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY saleprice) as q1_sale_price,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY saleprice) as median_sale_price,\n",
    "    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY saleprice) as q3_sale_price,\n",
    "    PERCENTILE_CONT(0.90) WITHIN GROUP (ORDER BY saleprice) as p90_sale_price,\n",
    "    PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY saleprice) as p95_sale_price,\n",
    "    PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY saleprice) as p99_sale_price,\n",
    "    -- Discrete percentiles\n",
    "    PERCENTILE_DISC(0.50) WITHIN GROUP (ORDER BY saleprice) as discrete_median,\n",
    "    PERCENTILE_DISC(0.90) WITHIN GROUP (ORDER BY saleprice) as discrete_p90,\n",
    "    -- Distribution metrics\n",
    "    MIN(saleprice) as min_price,\n",
    "    MAX(saleprice) as max_price,\n",
    "    CURRENT_TIMESTAMP() as analysis_timestamp\n",
    "FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cross_partition_analytics_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 2: Cross-Partition Analytics Dynamic Table (Full Refresh Mode)\n",
    "-- Demonstrates window functions spanning entire dataset without partitioning\n",
    "CREATE OR REPLACE DYNAMIC TABLE cross_partition_analytics\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    customer_id,\n",
    "    customer_name,\n",
    "    product_id,\n",
    "    saleprice,\n",
    "    creationtime,\n",
    "    -- Cross-partition window functions requiring full dataset knowledge\n",
    "    SUM(saleprice) OVER () as total_sales_across_all_data,\n",
    "    AVG(saleprice) OVER () as overall_average_sale_price,\n",
    "    COUNT(*) OVER () as total_transaction_count,\n",
    "    -- Running totals across entire unpartitioned dataset\n",
    "    SUM(saleprice) OVER (ORDER BY creationtime ROWS UNBOUNDED PRECEDING) as running_total_all_sales,\n",
    "    -- Percentage of total sales\n",
    "    ROUND((saleprice / SUM(saleprice) OVER ()) * 100, 4) as pct_of_total_sales,\n",
    "    -- Global standard deviation and variance\n",
    "    STDDEV(saleprice) OVER () as global_price_stddev,\n",
    "    VARIANCE(saleprice) OVER () as global_price_variance,\n",
    "    -- Global min/max\n",
    "    MIN(saleprice) OVER () as global_min_price,\n",
    "    MAX(saleprice) OVER () as global_max_price\n",
    "FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "advanced_statistics_analysis_dt"
   },
   "outputs": [],
   "source": [
    "-- Example 3: Complex Statistical Functions Dynamic Table (Full Refresh Mode)\n",
    "-- Demonstrates advanced statistical calculations requiring full dataset\n",
    "CREATE OR REPLACE DYNAMIC TABLE advanced_statistics_analysis\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE = XSMALL_WH\n",
    "AS\n",
    "SELECT \n",
    "    'STATISTICAL_ANALYSIS' as analysis_type,\n",
    "    COUNT(*) as sample_size,\n",
    "    -- Complex statistical functions requiring complete dataset\n",
    "    AVG(saleprice) as mean_sale_price,\n",
    "    STDDEV(saleprice) as price_std_deviation,\n",
    "    VARIANCE(saleprice) as price_variance,\n",
    "    STDDEV_POP(saleprice) as price_std_dev_population,\n",
    "    VAR_POP(saleprice) as price_variance_population,\n",
    "    -- Correlation analysis (requires multiple columns and full dataset)\n",
    "    CORR(saleprice, quantity) as price_quantity_correlation,\n",
    "    -- Advanced statistical measures\n",
    "    SKEW(saleprice) as price_skewness,\n",
    "    KURTOSIS(saleprice) as price_kurtosis,\n",
    "    -- Distribution analysis\n",
    "    (MAX(saleprice) - MIN(saleprice)) as price_range,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY saleprice) as median_price,\n",
    "    (PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY saleprice) - \n",
    "     PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY saleprice)) as interquartile_range,\n",
    "    -- Count of outliers (values beyond 2 standard deviations)\n",
    "    SUM(CASE WHEN ABS(saleprice - AVG(saleprice) OVER()) > 2 * STDDEV(saleprice) OVER() THEN 1 ELSE 0 END) as outlier_count,\n",
    "    CURRENT_TIMESTAMP() as analysis_timestamp\n",
    "FROM salesreport;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "verify_complex_analytics_dts"
   },
   "outputs": [],
   "source": [
    "-- Verify Complex Analytics Dynamic Tables\n",
    "SELECT 'SALES_PERCENTILE_ANALYSIS' as table_name, COUNT(*) as record_count FROM sales_percentile_analysis\n",
    "UNION ALL\n",
    "SELECT 'CROSS_PARTITION_ANALYTICS' as table_name, COUNT(*) as record_count FROM cross_partition_analytics\n",
    "UNION ALL\n",
    "SELECT 'ADVANCED_STATISTICS_ANALYSIS' as table_name, COUNT(*) as record_count FROM advanced_statistics_analysis;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "test_complex_analytics"
   },
   "outputs": [],
   "source": [
    "-- Test Complex Analytics - Insert new data\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(2500, 1));\n",
    "\n",
    "-- Check updated base table count\n",
    "SELECT 'SALESDATA_COMPLEX_ANALYTICS_TEST' as table_name, COUNT(*) as record_count FROM salesdata;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "check_complex_analytics_history"
   },
   "outputs": [],
   "source": [
    "-- Check Complex Analytics refresh history\n",
    "-- These should show REFRESH_TYPE = 'FULL' due to complex analytical requirements\n",
    "SELECT \n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_TYPE,\n",
    "    REFRESH_REASON,\n",
    "    DATA_TIMESTAMP,\n",
    "    REFRESH_START_TIME,\n",
    "    REFRESH_END_TIME,\n",
    "    CREDITS_USED,\n",
    "    BYTES_SCANNED,\n",
    "    ROWS_PRODUCED,\n",
    "    -- Highlight the complexity and refresh requirements\n",
    "    CASE \n",
    "        WHEN REFRESH_TYPE = 'FULL' THEN '⚠ FULL REFRESH - Complex Analytics'\n",
    "        WHEN REFRESH_TYPE = 'INCREMENTAL' THEN '✓ INCREMENTAL REFRESH'\n",
    "        ELSE '? UNKNOWN TYPE'\n",
    "    END as analytics_refresh_indicator,\n",
    "    -- Performance metrics for full refresh operations\n",
    "    ROUND(CREDITS_USED, 4) as credits_consumed,\n",
    "    ROUND(BYTES_SCANNED / 1024 / 1024, 2) as mb_scanned\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALES_PERCENTILE_ANALYSIS', 'CROSS_PARTITION_ANALYTICS', 'ADVANCED_STATISTICS_ANALYSIS')\n",
    "    AND REFRESH_START_TIME >= DATEADD('hour', -1, CURRENT_TIMESTAMP())\n",
    "ORDER BY \n",
    "    NAME, DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86f581e-3d8b-4dd0-b444-88d5fe00a27d",
   "metadata": {
    "language": "sql",
    "name": "check_salesreport_count",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Check Dynamic Tables after refresh (wait a minute for automatic refresh)\n",
    "SELECT COUNT(*) as salesreport_count FROM salesreport;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000018",
   "metadata": {
    "name": "python_udtf_overview"
   },
   "source": [
    "## Dynamic Tables with Python UDTFs\n",
    "\n",
    "We'll create a Python UDTF for cumulative sum calculations and use it in a Dynamic Table to demonstrate how to combine Python functions with Dynamic Tables for advanced analytics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000019",
   "metadata": {
    "language": "sql",
    "name": "create_cumulative_sum_udtf",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Python UDTF for cumulative sum calculation\n",
    "USE SCHEMA DEMO.DT_DEMO;\n",
    "\n",
    "CREATE OR REPLACE FUNCTION sum_table (INPUT_NUMBER number)\n",
    "  RETURNS TABLE (running_total number)\n",
    "  LANGUAGE PYTHON\n",
    "  RUNTIME_VERSION = '3.10'\n",
    "  HANDLER = 'gen_sum_table'\n",
    "AS\n",
    "$$\n",
    "# Define handler class\n",
    "class gen_sum_table :\n",
    "\n",
    "  ## Define __init__ method to initialize the variable\n",
    "  def __init__(self) :\n",
    "    self._running_sum = 0\n",
    "  \n",
    "  ## Define process method\n",
    "  def process(self, input_number: float) :\n",
    "    # Increment running sum with data from the input row\n",
    "    new_total = self._running_sum + input_number\n",
    "    self._running_sum = new_total\n",
    "\n",
    "    yield(new_total,)\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000020",
   "metadata": {
    "language": "sql",
    "name": "cumulative_purchase_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Dynamic Table using Python UDTF for cumulative purchase totals\n",
    "CREATE OR REPLACE DYNAMIC TABLE cumulative_purchase\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE=XSMALL_WH\n",
    "AS\n",
    "    SELECT \n",
    "        MONTH(creationtime) monthNum,\n",
    "        YEAR(creationtime) yearNum,\n",
    "        customer_id, \n",
    "        saleprice,\n",
    "        running_total \n",
    "    FROM \n",
    "        salesreport,\n",
    "        TABLE(sum_table(saleprice) OVER (PARTITION BY creationtime,customer_id ORDER BY creationtime, customer_id));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "metadata": {
    "language": "sql",
    "name": "verify_cumulative_purchase",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Verify cumulative purchase calculations\n",
    "SELECT * FROM cumulative_purchase LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "name": "validation_alerting_overview"
   },
   "source": [
    "## Data Validation and Alerting with Dynamic Tables\n",
    "\n",
    "Create a Dynamic Table for inventory monitoring that identifies products with low stock levels and set up automated alerts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000023",
   "metadata": {
    "language": "sql",
    "name": "prod_inv_alert_dt",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create Dynamic Table for product inventory alerts\n",
    "USE SCHEMA DEMO.DT_DEMO;\n",
    "\n",
    "CREATE OR REPLACE DYNAMIC TABLE PROD_INV_ALERT\n",
    "    LAG = '1 MINUTE'\n",
    "    WAREHOUSE=XSMALL_WH\n",
    "AS\n",
    "    SELECT \n",
    "        S.PRODUCT_ID, \n",
    "        S.PRODUCT_NAME,\n",
    "        CREATIONTIME AS LATEST_SALES_DATE,\n",
    "        STOCK AS BEGINING_STOCK,\n",
    "        SUM(S.QUANTITY) OVER (PARTITION BY S.PRODUCT_ID ORDER BY CREATIONTIME) TOTALUNITSOLD, \n",
    "        (STOCK - TOTALUNITSOLD) AS UNITSLEFT,\n",
    "        ROUND(((STOCK-TOTALUNITSOLD)/STOCK) *100,2) PERCENT_UNITLEFT,\n",
    "        CURRENT_TIMESTAMP() AS ROWCREATIONTIME\n",
    "    FROM SALESREPORT S JOIN PROD_STOCK_INV ON PRODUCT_ID = PID\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY PRODUCT_ID ORDER BY CREATIONTIME DESC) = 1;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "validate_incremental_refresh"
   },
   "outputs": [],
   "source": [
    "-- Add new sales data to test incremental refresh behavior\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(5000,1));\n",
    "\n",
    "-- Wait for Dynamic Tables to refresh (they have 1 MINUTE lag), then validate incremental processing\n",
    "-- This query should be run after ~1-2 minutes to allow Dynamic Tables to refresh\n",
    "\n",
    "-- IMPORTANT: Run this query after waiting 1-2 minutes for the Dynamic Tables to refresh\n",
    "SELECT \n",
    "    'INCREMENTAL_REFRESH_VALIDATION' as analysis_type,\n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_MODE as actual_refresh_mode,\n",
    "    REFRESH_MODE_REASON as mode_explanation,\n",
    "    DATEDIFF('seconds', REFRESH_START_TIME, REFRESH_END_TIME) as refresh_duration_seconds,\n",
    "    ROWS_PRODUCED as rows_affected_by_refresh,\n",
    "    BYTES_SCANNED as bytes_processed,\n",
    "    CREDITS_USED as warehouse_credits,\n",
    "    -- Key indicator: For incremental refresh, ROWS_PRODUCED should be much less than total table size\n",
    "    CASE \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED < 1000 \n",
    "        THEN '✓ CONFIRMED INCREMENTAL' \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED >= 1000 \n",
    "        THEN '⚠ INCREMENTAL BUT HIGH ROW COUNT'\n",
    "        WHEN REFRESH_MODE = 'FULL' \n",
    "        THEN '✗ FULL REFRESH OCCURRED'\n",
    "        ELSE '? UNKNOWN STATE'\n",
    "    END as incremental_validation_status\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALES_AGGREGATIONS','RECENT_HIGH_VALUE_SALES','CUSTOMER_PRODUCT_ANALYSIS','UNIFIED_TRANSACTION_FEED')\n",
    "    AND REFRESH_START_TIME > DATEADD('minute', -5, CURRENT_TIMESTAMP())  -- Only recent refreshes\n",
    "    AND DATA_TIMESTAMP IS NOT NULL\n",
    "ORDER BY \n",
    "    REFRESH_START_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000024",
   "metadata": {
    "language": "sql",
    "name": "check_low_inventory",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Check for products with low inventory (less than 10%)\n",
    "SELECT * FROM prod_inv_alert WHERE percent_unitleft < 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000025",
   "metadata": {
    "language": "sql",
    "name": "create_inventory_alert",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Create notification integration and alert for low inventory\n",
    "-- Note: Update email address before running\n",
    "CREATE OR REPLACE NOTIFICATION INTEGRATION -- IF NOT EXISTS\n",
    "    notification_emailer\n",
    "    TYPE=EMAIL\n",
    "    ENABLED=TRUE\n",
    "    ALLOWED_RECIPIENTS=('aaron.gavic@snowflake.com')  -- UPDATE THIS EMAIL\n",
    "    COMMENT = 'email integration to update on low product inventory levels';\n",
    "\n",
    "CREATE OR REPLACE ALERT alert_low_inv\n",
    "  WAREHOUSE = XSMALL_WH\n",
    "  SCHEDULE = '30 MINUTE'\n",
    "  IF (EXISTS (\n",
    "      SELECT *\n",
    "      FROM prod_inv_alert\n",
    "      WHERE percent_unitleft < 10 AND ROWCREATIONTIME > SNOWFLAKE.ALERT.LAST_SUCCESSFUL_SCHEDULED_TIME()\n",
    "  ))\n",
    "  THEN CALL SYSTEM$SEND_EMAIL(\n",
    "                'notification_emailer', -- notification integration to use\n",
    "                'aaron.gavic@snowflake.com', -- Email (UPDATE THIS)\n",
    "                'Email Alert: Low Inventory of products', -- Subject\n",
    "                'Inventory running low for certain products. Please check the inventory report in Snowflake table prod_inv_alert' -- Body of email\n",
    ");\n",
    "\n",
    "-- Alerts are paused by default, so resume it\n",
    "ALTER ALERT alert_low_inv RESUME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000026",
   "metadata": {
    "language": "sql",
    "name": "trigger_alert_data",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Add more sales data to potentially trigger alerts\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(10000,2));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000027",
   "metadata": {
    "name": "monitoring_overview"
   },
   "source": [
    "## Monitoring and Management\n",
    "\n",
    "Dynamic Tables provide comprehensive monitoring capabilities to track refresh history, performance, and troubleshoot issues.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000028",
   "metadata": {
    "language": "sql",
    "name": "monitor_refresh_history",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Monitor Dynamic Tables refresh history\n",
    "SELECT * \n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALESREPORT','CUSTOMER_SALES_DATA_HISTORY','PROD_INV_ALERT','CUMULATIVE_PURCHASE')\n",
    "ORDER BY \n",
    "    DATA_TIMESTAMP DESC, REFRESH_END_TIME DESC \n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000029",
   "metadata": {
    "language": "sql",
    "name": "show_dynamic_tables",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Show Dynamic Tables information and refresh modes\n",
    "SHOW DYNAMIC TABLES;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000030",
   "metadata": {
    "language": "sql",
    "name": "show_alerts",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Monitor alerts\n",
    "SHOW ALERTS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dac82-8efb-4441-8ceb-f9d3d5851cca",
   "metadata": {
    "language": "sql",
    "name": "check_alert_history"
   },
   "outputs": [],
   "source": [
    "SELECT *\n",
    "FROM\n",
    "  TABLE(INFORMATION_SCHEMA.ALERT_HISTORY(\n",
    "    SCHEDULED_TIME_RANGE_START\n",
    "      =>DATEADD('hour',-1,CURRENT_TIMESTAMP())))\n",
    "WHERE\n",
    "    NAME = 'ALERT_LOW_INV'\n",
    "ORDER BY SCHEDULED_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000031",
   "metadata": {
    "name": "operations_overview"
   },
   "source": [
    "## Dynamic Table Operations\n",
    "\n",
    "Dynamic Tables can be suspended, resumed, and manually refreshed as needed for operational control.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000032",
   "metadata": {
    "language": "sql",
    "name": "suspend_dynamic_tables",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Suspend Dynamic Tables (stops automatic refresh)\n",
    "ALTER DYNAMIC TABLE customer_sales_data_history SUSPEND;\n",
    "ALTER DYNAMIC TABLE salesreport SUSPEND;\n",
    "ALTER DYNAMIC TABLE prod_inv_alert SUSPEND;\n",
    "ALTER DYNAMIC TABLE cumulative_purchase SUSPEND;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000033",
   "metadata": {
    "language": "sql",
    "name": "resume_dynamic_tables",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Resume Dynamic Tables (restarts automatic refresh)\n",
    "ALTER DYNAMIC TABLE customer_sales_data_history RESUME;\n",
    "ALTER DYNAMIC TABLE salesreport RESUME;\n",
    "ALTER DYNAMIC TABLE prod_inv_alert RESUME;\n",
    "ALTER DYNAMIC TABLE cumulative_purchase RESUME;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000034",
   "metadata": {
    "language": "sql",
    "name": "manual_refresh",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Manually refresh a Dynamic Table\n",
    "ALTER DYNAMIC TABLE salesreport REFRESH;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000035",
   "metadata": {
    "name": "cleanup_overview"
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "**Important:** Run this section to prevent ongoing warehouse costs and credit consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "language": "sql",
    "name": "suspend_all_objects",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Suspend all Dynamic Tables to stop refresh cycles\n",
    "ALTER DYNAMIC TABLE customer_sales_data_history SUSPEND;\n",
    "ALTER DYNAMIC TABLE salesreport SUSPEND;\n",
    "ALTER DYNAMIC TABLE prod_inv_alert SUSPEND;\n",
    "ALTER DYNAMIC TABLE cumulative_purchase SUSPEND;\n",
    "\n",
    "-- Suspend Basic Incremental Operations Dynamic Tables\n",
    "ALTER DYNAMIC TABLE daily_sales_summary SUSPEND;\n",
    "ALTER DYNAMIC TABLE high_value_recent_sales SUSPEND;\n",
    "ALTER DYNAMIC TABLE customer_purchase_analysis SUSPEND;\n",
    "ALTER DYNAMIC TABLE unified_transaction_log SUSPEND;\n",
    "\n",
    "-- Suspend Complex Incremental Operations Dynamic Tables\n",
    "ALTER DYNAMIC TABLE json_sales_flattened SUSPEND;\n",
    "ALTER DYNAMIC TABLE customer_segmentation_cte SUSPEND;\n",
    "ALTER DYNAMIC TABLE sales_trends_window SUSPEND;\n",
    "ALTER DYNAMIC TABLE latest_customer_transactions SUSPEND;\n",
    "\n",
    "-- Suspend Non-Deterministic Functions Dynamic Tables\n",
    "ALTER DYNAMIC TABLE any_value_customer_sample SUSPEND;\n",
    "ALTER DYNAMIC TABLE customer_spending_ranks SUSPEND;\n",
    "ALTER DYNAMIC TABLE global_transaction_sequence SUSPEND;\n",
    "\n",
    "-- Suspend Complex Analytics Dynamic Tables\n",
    "ALTER DYNAMIC TABLE sales_percentile_analysis SUSPEND;\n",
    "ALTER DYNAMIC TABLE cross_partition_analytics SUSPEND;\n",
    "ALTER DYNAMIC TABLE advanced_statistics_analysis SUSPEND;\n",
    "\n",
    "-- Suspend alert to stop consuming warehouse credits\n",
    "ALTER ALERT alert_low_inv SUSPEND;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "incremental_validation_duplicate1"
   },
   "outputs": [],
   "source": [
    "-- Add new sales data to test incremental refresh behavior\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(5000,1));\n",
    "\n",
    "-- Wait for Dynamic Tables to refresh (they have 1 MINUTE lag), then validate incremental processing\n",
    "-- This query should be run after ~1-2 minutes to allow Dynamic Tables to refresh\n",
    "\n",
    "-- IMPORTANT: Run this query after waiting 1-2 minutes for the Dynamic Tables to refresh\n",
    "SELECT \n",
    "    'INCREMENTAL_REFRESH_VALIDATION' as analysis_type,\n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_MODE as actual_refresh_mode,\n",
    "    REFRESH_MODE_REASON as mode_explanation,\n",
    "    DATEDIFF('seconds', REFRESH_START_TIME, REFRESH_END_TIME) as refresh_duration_seconds,\n",
    "    ROWS_PRODUCED as rows_affected_by_refresh,\n",
    "    BYTES_SCANNED as bytes_processed,\n",
    "    CREDITS_USED as warehouse_credits,\n",
    "    -- Key indicator: For incremental refresh, ROWS_PRODUCED should be much less than total table size\n",
    "    CASE \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED < 1000 \n",
    "        THEN '✓ CONFIRMED INCREMENTAL' \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED >= 1000 \n",
    "        THEN '⚠ INCREMENTAL BUT HIGH ROW COUNT'\n",
    "        WHEN REFRESH_MODE = 'FULL' \n",
    "        THEN '✗ FULL REFRESH OCCURRED'\n",
    "        ELSE '? UNKNOWN STATE'\n",
    "    END as incremental_validation_status\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALES_AGGREGATIONS','RECENT_HIGH_VALUE_SALES','CUSTOMER_PRODUCT_ANALYSIS','UNIFIED_TRANSACTION_FEED')\n",
    "    AND REFRESH_START_TIME > DATEADD('minute', -5, CURRENT_TIMESTAMP())  -- Only recent refreshes\n",
    "    AND DATA_TIMESTAMP IS NOT NULL\n",
    "ORDER BY \n",
    "    REFRESH_START_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "incremental_validation_duplicate2"
   },
   "outputs": [],
   "source": [
    "-- Add new sales data to test incremental refresh behavior\n",
    "INSERT INTO salesdata SELECT * FROM table(gen_cust_purchase(5000,1));\n",
    "\n",
    "-- Wait for Dynamic Tables to refresh (they have 1 MINUTE lag), then validate incremental processing\n",
    "-- This query should be run after ~1-2 minutes to allow Dynamic Tables to refresh\n",
    "\n",
    "-- IMPORTANT: Run this query after waiting 1-2 minutes for the Dynamic Tables to refresh\n",
    "SELECT \n",
    "    'INCREMENTAL_REFRESH_VALIDATION' as analysis_type,\n",
    "    NAME as dynamic_table_name,\n",
    "    REFRESH_MODE as actual_refresh_mode,\n",
    "    REFRESH_MODE_REASON as mode_explanation,\n",
    "    DATEDIFF('seconds', REFRESH_START_TIME, REFRESH_END_TIME) as refresh_duration_seconds,\n",
    "    ROWS_PRODUCED as rows_affected_by_refresh,\n",
    "    BYTES_SCANNED as bytes_processed,\n",
    "    CREDITS_USED as warehouse_credits,\n",
    "    -- Key indicator: For incremental refresh, ROWS_PRODUCED should be much less than total table size\n",
    "    CASE \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED < 1000 \n",
    "        THEN '✓ CONFIRMED INCREMENTAL' \n",
    "        WHEN REFRESH_MODE = 'INCREMENTAL' AND ROWS_PRODUCED >= 1000 \n",
    "        THEN '⚠ INCREMENTAL BUT HIGH ROW COUNT'\n",
    "        WHEN REFRESH_MODE = 'FULL' \n",
    "        THEN '✗ FULL REFRESH OCCURRED'\n",
    "        ELSE '? UNKNOWN STATE'\n",
    "    END as incremental_validation_status\n",
    "FROM \n",
    "    TABLE(INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY())\n",
    "WHERE \n",
    "    NAME IN ('SALES_AGGREGATIONS','RECENT_HIGH_VALUE_SALES','CUSTOMER_PRODUCT_ANALYSIS','UNIFIED_TRANSACTION_FEED')\n",
    "    AND REFRESH_START_TIME > DATEADD('minute', -5, CURRENT_TIMESTAMP())  -- Only recent refreshes\n",
    "    AND DATA_TIMESTAMP IS NOT NULL\n",
    "ORDER BY \n",
    "    REFRESH_START_TIME DESC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000037",
   "metadata": {
    "language": "sql",
    "name": "optional_complete_cleanup",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Optional: Complete cleanup by dropping all demo objects\n",
    "-- Uncomment the lines below if you want to remove all demo objects\n",
    "\n",
    " DROP SCHEMA DEMO.DT_DEMO CASCADE;\n",
    " DROP DATABASE DEMO;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000038",
   "metadata": {
    "name": "summary_conclusion"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key capabilities of Snowflake Dynamic Tables:\n",
    "\n",
    "- **Declarative Pipeline Creation:** Define data transformations with simple SQL queries\n",
    "- **Automatic Orchestration:** Snowflake manages refresh scheduling based on target lag\n",
    "- **Incremental Processing:** Efficient updates that process only changed data\n",
    "- **Python Integration:** Use UDTFs for advanced analytics within Dynamic Tables\n",
    "- **Data Validation:** Build automated data quality checks and alerts\n",
    "- **Monitoring:** Comprehensive observability through built-in functions and Snowsight\n",
    "- **Operational Control:** Suspend, resume, and manually refresh as needed\n",
    "\n",
    "Dynamic Tables simplify data engineering by providing a declarative approach to building continuous data pipelines without the complexity of traditional orchestration tools.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "aaron.gavic@snowflake.com",
   "authorId": "15462019492",
   "authorName": "JOHN",
   "lastEditTime": 1753853218111,
   "notebookId": "nfwf426e3hogi6khvj2q",
   "sessionId": "b4236791-1bd6-4e28-8914-7e224fecc0ee"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}