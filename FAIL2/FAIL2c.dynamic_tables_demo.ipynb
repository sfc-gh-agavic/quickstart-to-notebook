{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Snowflake Dynamic Tables Demo\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates Snowflake's Dynamic Tables functionality using the TPC-H sample dataset. We'll explore:\n",
        "- **Incremental refresh patterns** (cost-efficient, real-time)\n",
        "- **Full refresh strategies** (accuracy-focused, batch)\n",
        "- **Cascading pipeline dependencies**\n",
        "\n",
        "## What are Dynamic Tables?\n",
        "Dynamic Tables in Snowflake automatically refresh data based on changes in underlying tables, providing:\n",
        "- Automated data pipeline management\n",
        "- Flexible refresh strategies (incremental vs full)\n",
        "- Dependency-aware refresh ordering\n",
        "- Cost optimization through intelligent refresh scheduling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Setup and Connection\n",
        "\n",
        "First, let's establish connection to Snowflake and set up our environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import snowflake.connector\n",
        "import pandas as pd\n",
        "from snowflake.connector.pandas_tools import write_pandas\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Connection parameters (update with your credentials)\n",
        "conn_params = {\n",
        "    'user': os.getenv('SNOWFLAKE_USER', 'your_username'),\n",
        "    'password': os.getenv('SNOWFLAKE_PASSWORD', 'your_password'),\n",
        "    'account': os.getenv('SNOWFLAKE_ACCOUNT', 'your_account'),\n",
        "    'warehouse': 'COMPUTE_WH',\n",
        "    'database': 'DEMO_DB',\n",
        "    'schema': 'DYNAMIC_TABLES'\n",
        "}\n",
        "\n",
        "# Establish connection\n",
        "try:\n",
        "    conn = snowflake.connector.connect(**conn_params)\n",
        "    cursor = conn.cursor()\n",
        "    print(\"‚úÖ Successfully connected to Snowflake!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Connection failed: {e}\")\n",
        "    print(\"Please update your connection parameters above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Explore TPC-H Sample Data\n",
        "\n",
        "Let's examine the existing TPC-H dataset in Snowflake's sample data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Explore available tables in TPC-H dataset\n",
        "cursor.execute(\"SHOW TABLES IN SCHEMA SFC_SAMPLE_DATA.TPCH_SF1\")\n",
        "tables = cursor.fetchall()\n",
        "\n",
        "print(\"üìä Available TPC-H Tables:\")\n",
        "for table in tables:\n",
        "    print(f\"  - {table[1]}\")  # table name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine key tables structure and sample data\n",
        "key_tables = ['ORDERS', 'CUSTOMER', 'LINEITEM', 'PART']\n",
        "\n",
        "for table in key_tables:\n",
        "    print(f\"\\nüîç Table: {table}\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Show structure\n",
        "    cursor.execute(f\"DESCRIBE TABLE SFC_SAMPLE_DATA.TPCH_SF1.{table}\")\n",
        "    columns = cursor.fetchall()\n",
        "    print(\"Columns:\")\n",
        "    for col in columns[:5]:  # Show first 5 columns\n",
        "        print(f\"  - {col[0]}: {col[1]}\")\n",
        "    if len(columns) > 5:\n",
        "        print(f\"  ... and {len(columns) - 5} more columns\")\n",
        "    \n",
        "    # Show row count\n",
        "    cursor.execute(f\"SELECT COUNT(*) FROM SFC_SAMPLE_DATA.TPCH_SF1.{table}\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"Row count: {count:,}\")\n",
        "    \n",
        "    # Show sample data\n",
        "    cursor.execute(f\"SELECT * FROM SFC_SAMPLE_DATA.TPCH_SF1.{table} LIMIT 3\")\n",
        "    sample_data = cursor.fetchall()\n",
        "    print(\"Sample data:\")\n",
        "    for row in sample_data:\n",
        "        print(f\"  {row[:3]}...\")  # Show first 3 columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Create Demo Database and Schema\n",
        "\n",
        "Set up our demo environment for Dynamic Tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create demo database and schema\n",
        "setup_commands = [\n",
        "    \"CREATE DATABASE IF NOT EXISTS DEMO_DB\",\n",
        "    \"USE DATABASE DEMO_DB\",\n",
        "    \"CREATE SCHEMA IF NOT EXISTS DYNAMIC_TABLES\",\n",
        "    \"USE SCHEMA DYNAMIC_TABLES\"\n",
        "]\n",
        "\n",
        "for cmd in setup_commands:\n",
        "    try:\n",
        "        cursor.execute(cmd)\n",
        "        print(f\"‚úÖ {cmd}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error executing '{cmd}': {e}\")\n",
        "\n",
        "print(\"\\nüèóÔ∏è Demo environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Dynamic Table Example 1: Incremental Refresh Pattern\n",
        "\n",
        "Create a Dynamic Table that aggregates order data with **incremental refresh** for cost-efficiency and real-time updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dynamic Table with incremental refresh (LAG = '5 minutes')\n",
        "incremental_dt_sql = \"\"\"\n",
        "CREATE OR REPLACE DYNAMIC TABLE customer_order_summary_incremental\n",
        "TARGET_LAG = '5 minutes'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "AS\n",
        "SELECT \n",
        "    c.C_CUSTKEY,\n",
        "    c.C_NAME,\n",
        "    c.C_NATIONKEY,\n",
        "    COUNT(o.O_ORDERKEY) AS total_orders,\n",
        "    SUM(o.O_TOTALPRICE) AS total_spent,\n",
        "    AVG(o.O_TOTALPRICE) AS avg_order_value,\n",
        "    MAX(o.O_ORDERDATE) AS last_order_date,\n",
        "    CURRENT_TIMESTAMP() AS last_updated\n",
        "FROM SFC_SAMPLE_DATA.TPCH_SF1.CUSTOMER c\n",
        "LEFT JOIN SFC_SAMPLE_DATA.TPCH_SF1.ORDERS o ON c.C_CUSTKEY = o.O_CUSTKEY\n",
        "GROUP BY c.C_CUSTKEY, c.C_NAME, c.C_NATIONKEY\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    cursor.execute(incremental_dt_sql)\n",
        "    print(\"‚úÖ Created Dynamic Table: customer_order_summary_incremental\")\n",
        "    print(\"üìà Refresh Mode: Incremental (TARGET_LAG = '5 minutes')\")\n",
        "    print(\"üí° Use case: Real-time customer analytics dashboard\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating incremental Dynamic Table: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the incremental Dynamic Table data\n",
        "cursor.execute(\"SELECT * FROM customer_order_summary_incremental LIMIT 10\")\n",
        "incremental_data = cursor.fetchall()\n",
        "\n",
        "print(\"üìä Sample data from incremental Dynamic Table:\")\n",
        "print(\"CUSTKEY | NAME | TOTAL_ORDERS | TOTAL_SPENT | AVG_ORDER_VALUE\")\n",
        "print(\"-\" * 70)\n",
        "for row in incremental_data:\n",
        "    print(f\"{row[0]} | {row[1][:20]:<20} | {row[3]:>12} | {row[4]:>11.2f} | {row[5]:>15.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Dynamic Table Example 2: Full Refresh Strategy\n",
        "\n",
        "Create a Dynamic Table with **full refresh** for accuracy-focused, batch processing scenarios.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dynamic Table with full refresh (LAG = '1 hour')\n",
        "full_refresh_dt_sql = \"\"\"\n",
        "CREATE OR REPLACE DYNAMIC TABLE product_sales_analysis_full\n",
        "TARGET_LAG = '1 hour'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "REFRESH_MODE = FULL\n",
        "AS\n",
        "SELECT \n",
        "    p.P_PARTKEY,\n",
        "    p.P_NAME,\n",
        "    p.P_BRAND,\n",
        "    p.P_TYPE,\n",
        "    p.P_SIZE,\n",
        "    COUNT(l.L_ORDERKEY) AS total_orders,\n",
        "    SUM(l.L_QUANTITY) AS total_quantity_sold,\n",
        "    SUM(l.L_EXTENDEDPRICE) AS total_revenue,\n",
        "    AVG(l.L_EXTENDEDPRICE / l.L_QUANTITY) AS avg_unit_price,\n",
        "    SUM(l.L_EXTENDEDPRICE * (1 - l.L_DISCOUNT)) AS net_revenue,\n",
        "    CURRENT_TIMESTAMP() AS analysis_timestamp\n",
        "FROM SFC_SAMPLE_DATA.TPCH_SF1.PART p\n",
        "LEFT JOIN SFC_SAMPLE_DATA.TPCH_SF1.LINEITEM l ON p.P_PARTKEY = l.L_PARTKEY\n",
        "GROUP BY p.P_PARTKEY, p.P_NAME, p.P_BRAND, p.P_TYPE, p.P_SIZE\n",
        "HAVING COUNT(l.L_ORDERKEY) > 0\n",
        "\"\"\"\n",
        "\n",
        "try:\n",
        "    cursor.execute(full_refresh_dt_sql)\n",
        "    print(\"‚úÖ Created Dynamic Table: product_sales_analysis_full\")\n",
        "    print(\"üîÑ Refresh Mode: Full (TARGET_LAG = '1 hour')\")\n",
        "    print(\"üí° Use case: Comprehensive product performance analysis\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error creating full refresh Dynamic Table: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the full refresh Dynamic Table data\n",
        "cursor.execute(\"SELECT * FROM product_sales_analysis_full ORDER BY total_revenue DESC LIMIT 10\")\n",
        "full_refresh_data = cursor.fetchall()\n",
        "\n",
        "print(\"üìä Top 10 products by revenue (Full Refresh Dynamic Table):\")\n",
        "print(\"PARTKEY | PRODUCT_NAME | BRAND | TOTAL_ORDERS | TOTAL_REVENUE\")\n",
        "print(\"-\" * 80)\n",
        "for row in full_refresh_data:\n",
        "    print(f\"{row[0]} | {row[1][:25]:<25} | {row[2]:<10} | {row[5]:>12} | {row[7]:>13.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Cascading Pipeline Dependencies\n",
        "\n",
        "Create a multi-layer pipeline where Dynamic Tables depend on each other, demonstrating cascading refresh behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Layer 1: Base aggregation (depends on source tables)\n",
        "layer1_sql = \"\"\"\n",
        "CREATE OR REPLACE DYNAMIC TABLE order_line_summary\n",
        "TARGET_LAG = '10 minutes'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "AS\n",
        "SELECT \n",
        "    o.O_ORDERKEY,\n",
        "    o.O_CUSTKEY,\n",
        "    o.O_ORDERDATE,\n",
        "    o.O_ORDERSTATUS,\n",
        "    COUNT(l.L_LINENUMBER) AS line_count,\n",
        "    SUM(l.L_QUANTITY) AS total_quantity,\n",
        "    SUM(l.L_EXTENDEDPRICE) AS order_total,\n",
        "    SUM(l.L_EXTENDEDPRICE * (1 - l.L_DISCOUNT)) AS net_total\n",
        "FROM SFC_SAMPLE_DATA.TPCH_SF1.ORDERS o\n",
        "JOIN SFC_SAMPLE_DATA.TPCH_SF1.LINEITEM l ON o.O_ORDERKEY = l.L_ORDERKEY\n",
        "GROUP BY o.O_ORDERKEY, o.O_CUSTKEY, o.O_ORDERDATE, o.O_ORDERSTATUS\n",
        "\"\"\"\n",
        "\n",
        "# Layer 2: Monthly aggregation (depends on Layer 1)\n",
        "layer2_sql = \"\"\"\n",
        "CREATE OR REPLACE DYNAMIC TABLE monthly_sales_summary\n",
        "TARGET_LAG = '30 minutes'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "AS\n",
        "SELECT \n",
        "    DATE_TRUNC('MONTH', O_ORDERDATE) AS sales_month,\n",
        "    O_ORDERSTATUS,\n",
        "    COUNT(O_ORDERKEY) AS orders_count,\n",
        "    SUM(line_count) AS total_lines,\n",
        "    SUM(total_quantity) AS total_quantity,\n",
        "    SUM(order_total) AS gross_revenue,\n",
        "    SUM(net_total) AS net_revenue,\n",
        "    AVG(order_total) AS avg_order_value\n",
        "FROM order_line_summary\n",
        "GROUP BY DATE_TRUNC('MONTH', O_ORDERDATE), O_ORDERSTATUS\n",
        "\"\"\"\n",
        "\n",
        "# Layer 3: KPI dashboard (depends on Layer 2)\n",
        "layer3_sql = \"\"\"\n",
        "CREATE OR REPLACE DYNAMIC TABLE sales_kpi_dashboard\n",
        "TARGET_LAG = '1 hour'\n",
        "WAREHOUSE = COMPUTE_WH\n",
        "AS\n",
        "SELECT \n",
        "    sales_month,\n",
        "    SUM(CASE WHEN O_ORDERSTATUS = 'F' THEN net_revenue ELSE 0 END) AS completed_revenue,\n",
        "    SUM(CASE WHEN O_ORDERSTATUS = 'O' THEN net_revenue ELSE 0 END) AS pending_revenue,\n",
        "    SUM(net_revenue) AS total_monthly_revenue,\n",
        "    COUNT(DISTINCT CASE WHEN O_ORDERSTATUS = 'F' THEN sales_month END) AS months_with_completed_orders,\n",
        "    AVG(avg_order_value) AS avg_monthly_order_value,\n",
        "    CURRENT_TIMESTAMP() AS dashboard_updated\n",
        "FROM monthly_sales_summary\n",
        "GROUP BY sales_month\n",
        "ORDER BY sales_month DESC\n",
        "\"\"\"\n",
        "\n",
        "# Execute cascading pipeline creation\n",
        "pipeline_steps = [\n",
        "    (\"Layer 1 - Order Line Summary\", layer1_sql),\n",
        "    (\"Layer 2 - Monthly Sales Summary\", layer2_sql), \n",
        "    (\"Layer 3 - Sales KPI Dashboard\", layer3_sql)\n",
        "]\n",
        "\n",
        "print(\"üîó Creating Cascading Pipeline:\")\n",
        "for step_name, sql in pipeline_steps:\n",
        "    try:\n",
        "        cursor.execute(sql)\n",
        "        print(f\"‚úÖ {step_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating {step_name}: {e}\")\n",
        "\n",
        "print(\"\\nüéØ Cascading pipeline created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View the final KPI dashboard\n",
        "cursor.execute(\"SELECT * FROM sales_kpi_dashboard LIMIT 10\")\n",
        "kpi_data = cursor.fetchall()\n",
        "\n",
        "print(\"üìà Sales KPI Dashboard (Final Layer):\")\n",
        "print(\"MONTH | COMPLETED_REV | PENDING_REV | TOTAL_REV | AVG_ORDER_VALUE\")\n",
        "print(\"-\" * 75)\n",
        "for row in kpi_data:\n",
        "    month = row[0].strftime(\"%Y-%m\") if row[0] else \"N/A\"\n",
        "    print(f\"{month} | {row[1]:>13.2f} | {row[2]:>11.2f} | {row[3]:>9.2f} | {row[5]:>15.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Monitoring and Performance\n",
        "\n",
        "Monitor Dynamic Table refresh status, performance, and dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor Dynamic Table status and metadata\n",
        "monitoring_queries = {\n",
        "    \"Dynamic Tables Overview\": \"\"\"\n",
        "    SELECT \n",
        "        name,\n",
        "        target_lag,\n",
        "        refresh_mode,\n",
        "        scheduling_state,\n",
        "        last_refresh_time,\n",
        "        next_refresh_time,\n",
        "        is_current\n",
        "    FROM INFORMATION_SCHEMA.DYNAMIC_TABLES \n",
        "    WHERE schema_name = 'DYNAMIC_TABLES'\n",
        "    ORDER BY name\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Refresh History\": \"\"\"\n",
        "    SELECT \n",
        "        dynamic_table_name,\n",
        "        refresh_start_time,\n",
        "        refresh_end_time,\n",
        "        DATEDIFF('seconds', refresh_start_time, refresh_end_time) AS duration_seconds,\n",
        "        refresh_trigger,\n",
        "        state\n",
        "    FROM INFORMATION_SCHEMA.DYNAMIC_TABLE_REFRESH_HISTORY \n",
        "    WHERE schema_name = 'DYNAMIC_TABLES'\n",
        "    ORDER BY refresh_start_time DESC\n",
        "    LIMIT 20\n",
        "    \"\"\",\n",
        "    \n",
        "    \"Dependencies Graph\": \"\"\"\n",
        "    SELECT \n",
        "        referenced_object_name AS source_table,\n",
        "        referencing_object_name AS dependent_table,\n",
        "        dependency_type\n",
        "    FROM INFORMATION_SCHEMA.OBJECT_DEPENDENCIES \n",
        "    WHERE referencing_object_domain = 'TABLE' \n",
        "    AND referenced_object_domain = 'TABLE'\n",
        "    AND (referencing_object_name LIKE '%summary%' OR referencing_object_name LIKE '%dashboard%')\n",
        "    ORDER BY dependent_table\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "for query_name, query in monitoring_queries.items():\n",
        "    print(f\"\\nüîç {query_name}\")\n",
        "    print(\"=\" * 60)\n",
        "    try:\n",
        "        cursor.execute(query)\n",
        "        results = cursor.fetchall()\n",
        "        if results:\n",
        "            for row in results[:5]:  # Limit to first 5 rows for readability\n",
        "                print(f\"  {row}\")\n",
        "            if len(results) > 5:\n",
        "                print(f\"  ... and {len(results) - 5} more rows\")\n",
        "        else:\n",
        "            print(\"  No data found\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Testing Different LAG Settings and Refresh Modes\n",
        "\n",
        "Compare performance and behavior of different configuration options.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test different LAG configurations\n",
        "test_configs = [\n",
        "    {\n",
        "        \"name\": \"high_frequency_orders\",\n",
        "        \"lag\": \"2 minutes\",\n",
        "        \"mode\": \"AUTO\",\n",
        "        \"sql\": \"\"\"\n",
        "        SELECT \n",
        "            O_ORDERSTATUS,\n",
        "            COUNT(*) AS status_count,\n",
        "            SUM(O_TOTALPRICE) AS total_value\n",
        "        FROM SFC_SAMPLE_DATA.TPCH_SF1.ORDERS \n",
        "        GROUP BY O_ORDERSTATUS\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"daily_batch_summary\", \n",
        "        \"lag\": \"1 day\",\n",
        "        \"mode\": \"FULL\",\n",
        "        \"sql\": \"\"\"\n",
        "        SELECT \n",
        "            DATE_TRUNC('DAY', O_ORDERDATE) AS order_day,\n",
        "            COUNT(*) AS daily_orders,\n",
        "            AVG(O_TOTALPRICE) AS avg_order_value,\n",
        "            MAX(O_TOTALPRICE) AS max_order_value\n",
        "        FROM SFC_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "        GROUP BY DATE_TRUNC('DAY', O_ORDERDATE)\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üß™ Testing Different LAG Settings:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for config in test_configs:\n",
        "    table_name = f\"test_{config['name']}\"\n",
        "    refresh_mode = f\"REFRESH_MODE = {config['mode']}\" if config['mode'] != 'AUTO' else \"\"\n",
        "    \n",
        "    create_sql = f\"\"\"\n",
        "    CREATE OR REPLACE DYNAMIC TABLE {table_name}\n",
        "    TARGET_LAG = '{config['lag']}'\n",
        "    WAREHOUSE = COMPUTE_WH\n",
        "    {refresh_mode}\n",
        "    AS\n",
        "    {config['sql']}\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        cursor.execute(create_sql)\n",
        "        print(f\"‚úÖ Created: {table_name}\")\n",
        "        print(f\"   LAG: {config['lag']}, Mode: {config['mode']}\")\n",
        "        \n",
        "        # Show sample data\n",
        "        cursor.execute(f\"SELECT * FROM {table_name} LIMIT 3\")\n",
        "        sample = cursor.fetchall()\n",
        "        print(f\"   Sample: {sample[0] if sample else 'No data'}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error creating {table_name}: {e}\")\n",
        "    \n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Summary and Best Practices\n",
        "\n",
        "Key takeaways and recommendations for using Dynamic Tables effectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### ‚ú® Demo Achievements\n",
        "\n",
        "‚úÖ **Incremental Refresh Pattern**: `customer_order_summary_incremental` (5-minute LAG)\n",
        "- Use case: Real-time customer analytics\n",
        "- Benefits: Cost-efficient, near real-time updates\n",
        "\n",
        "‚úÖ **Full Refresh Strategy**: `product_sales_analysis_full` (1-hour LAG) \n",
        "- Use case: Comprehensive product analysis\n",
        "- Benefits: Data accuracy, complex transformations\n",
        "\n",
        "‚úÖ **Cascading Pipeline Dependencies**: 3-layer architecture\n",
        "- Layer 1: `order_line_summary` (10 min)\n",
        "- Layer 2: `monthly_sales_summary` (30 min)  \n",
        "- Layer 3: `sales_kpi_dashboard` (1 hour)\n",
        "\n",
        "‚úÖ **Different LAG Settings**: From 2 minutes to 1 day\n",
        "‚úÖ **Monitoring Capabilities**: Status, history, dependencies\n",
        "\n",
        "### üéØ Best Practices Demonstrated\n",
        "\n",
        "1. **Choose Appropriate LAG Settings**\n",
        "   - Real-time dashboards: 1-15 minutes\n",
        "   - Operational reports: 30 minutes - 2 hours\n",
        "   - Analytical workloads: 4-24 hours\n",
        "\n",
        "2. **Select Refresh Mode Wisely**\n",
        "   - **AUTO (Incremental)**: For append-only or time-partitioned data\n",
        "   - **FULL**: For complex joins, aggregations, or when data integrity is critical\n",
        "\n",
        "3. **Design Efficient Pipelines**\n",
        "   - Start with base aggregations (frequent refresh)\n",
        "   - Build summary layers (moderate refresh)\n",
        "   - Create final KPIs (less frequent refresh)\n",
        "\n",
        "4. **Monitor and Optimize**\n",
        "   - Track refresh duration and frequency\n",
        "   - Monitor warehouse usage and costs\n",
        "   - Review dependency chains for bottlenecks\n",
        "\n",
        "### üîó Resources\n",
        "- [Dynamic Tables Quickstart](https://quickstarts.snowflake.com/guide/getting_started_with_dynamic_tables/)\n",
        "- [Dynamic Tables Documentation](https://docs.snowflake.com/en/user-guide/dynamic-tables-about)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean up connection\n",
        "cursor.close()\n",
        "conn.close()\n",
        "print(\"üîö Demo completed! Connection closed.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
